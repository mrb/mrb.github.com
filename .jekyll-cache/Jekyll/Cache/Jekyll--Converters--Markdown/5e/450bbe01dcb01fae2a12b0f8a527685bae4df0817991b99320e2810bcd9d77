I"Kh<p>#</p>

<div class="lead">This post is part of a series exploring <a href="http://www.info.ucl.ac.be/~pvr/book.html">Concepts, Techniques, and Models of Computer Programming</a> by Van Roy and Haridi. Check the <a href="/">blog index</a> for more.</div>

<p>#</p>
<h3 id="concurrency-made-simple">Concurrency Made Simple</h3>

<p>Chapters 3 and 4 of Concepts, Techniques, and Models of Computer Programming (CTM) cover the definition of declarativeness and its application in concurrent programing. <a href="http://michaelrbernste.in/2013/06/20/what-is-declarative-programming.html">As noted in the previous post in this series</a> which mostly covered Chapter 3, one of the limitations of the declarative paradigm is its inability to deal with the “real world.”<a href="#bib3">[3]</a> Declarative programming is <em>pure</em>, but not always <em>realistic.</em> The “real world” includes concurrency, the basic definition of which is “A set of activities that execute independently.” In other words, in the real world, things operate both in tandem with and independently from each other. Not everything can be neatly partitioned as declarative programming can sometimes require. Dealing with concurrency in programs is notoriously challenging, but not by necessity. The authors have developed a simple mantra:</p>

<blockquote>
  <p>“Concurrency can be simple.”</p>
</blockquote>

<p>They demonstrate the basic means by which a program can be made concurrent as follows. Consider this simple program in the declarative kernel language:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fun</span> <span class="p">{</span><span class="no">Gen</span> <span class="no">L</span> <span class="no">H</span><span class="p">}</span> 
	<span class="p">{</span><span class="no">Delay</span> <span class="mi">100</span><span class="p">}</span> 
	<span class="k">if</span> <span class="no">L</span><span class="o">&gt;</span><span class="no">H</span> <span class="k">then</span> <span class="kp">nil</span> <span class="k">else</span> <span class="no">L</span><span class="o">|</span><span class="p">{</span><span class="no">Gen</span> <span class="no">L</span><span class="o">+</span><span class="mi">1</span> <span class="no">H</span><span class="p">}</span> <span class="k">end</span>
<span class="k">end</span>

<span class="no">Xs</span><span class="o">=</span><span class="p">{</span><span class="no">Gen</span> <span class="mi">1</span> <span class="mi">10</span><span class="p">}</span> 
<span class="no">Ys</span><span class="o">=</span><span class="p">{</span><span class="no">Map</span> <span class="no">Xs</span> <span class="n">fun</span> <span class="p">{</span><span class="err">$</span> <span class="no">X</span><span class="p">}</span> <span class="no">X</span><span class="o">*</span><span class="no">X</span> <span class="k">end</span><span class="p">}</span>
<span class="p">{</span><span class="no">Browse</span> <span class="no">Ys</span><span class="p">}</span></code></pre></figure>

<p>A function <code class="language-plaintext highlighter-rouge">Gen</code> takes two variables <code class="language-plaintext highlighter-rouge">L</code> and <code class="language-plaintext highlighter-rouge">H</code>. It waits 100 milliseconds. It terminates if <code class="language-plaintext highlighter-rouge">L</code> is greater than <code class="language-plaintext highlighter-rouge">H</code>, else it recurs on a constructed list with <code class="language-plaintext highlighter-rouge">L</code> as the head and a new list beginning with <code class="language-plaintext highlighter-rouge">L+1</code> as the tail. When run with <code class="language-plaintext highlighter-rouge">{Gen 1 10}</code>, it would return a list <code class="language-plaintext highlighter-rouge">[1 2 3 4 5 6 7 8 9 10]</code> Below the function definition, the <code class="language-plaintext highlighter-rouge">1..10</code> list is bound to <code class="language-plaintext highlighter-rouge">Xs</code>, and <code class="language-plaintext highlighter-rouge">Ys</code> is bound to the results of mapping over the elements of <code class="language-plaintext highlighter-rouge">Xs</code> and squaring them. The results of the list are then shown with <code class="language-plaintext highlighter-rouge">Browse</code>.</p>

<p>The concurrent or threaded version uses the same definition for Gen, and only adds the <code class="language-plaintext highlighter-rouge">thread</code> keyword:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">thread</span> <span class="no">Xs</span><span class="o">=</span><span class="p">{</span><span class="no">Gen</span> <span class="mi">1</span> <span class="mi">10</span><span class="p">}</span> <span class="k">end</span>
<span class="n">thread</span> <span class="no">Ys</span><span class="o">=</span><span class="p">{</span><span class="no">Map</span> <span class="no">Xs</span> <span class="n">fun</span> <span class="p">{</span><span class="err">$</span> <span class="no">X</span><span class="p">}</span> <span class="no">X</span><span class="o">*</span><span class="no">X</span> <span class="k">end</span><span class="p">}</span>
<span class="p">{</span><span class="no">Browse</span> <span class="no">Ys</span><span class="p">}</span></code></pre></figure>

<p>The result is that the results are <em>incrementally</em> displayed in <code class="language-plaintext highlighter-rouge">Browse</code> as they are calculated. The reason to put a <code class="language-plaintext highlighter-rouge">Delay</code> call in <code class="language-plaintext highlighter-rouge">Gen</code> is to illustrate the point that <em>concurrency has the effect of making ‘atomic’ calculations ‘incremental’</em>. Note that nothing else about the program needed to change in order to make it concurrent: just add <code class="language-plaintext highlighter-rouge">threads</code> and you’re good. This is the dream of concurrent programming.</p>

<p>This post will cover the parts of Chapter 4 which define concurrency and its application to declarative programming. We will see the semantics of threads in the extended kernel language, get a glimpse at programming with streams, and I will attempt to tie the lessons of declarative concurrency to the current state of programming tools. I’m not covering everything in this chapter by a long shot - it is very dense. I’m intentionally not covering error handling or exceptions, which might rankle some, especially in the context of streams. If you want to know more about this, I suggest that you read the chapter: the authors have some good answers for you. Our next post will finish out Chapter 4 by taking a look at Declarative concurrency and its interaction with a fascinating language construct known as <em>laziness</em>.</p>

<h4 id="what-is-concurrency">What is Concurrency?</h4>

<p>Declarative programming has been shown to be a surprisingly rich and capable paradigm which can be applied in a variety of circumstances if the developer is aware of the involved tradeoffs. The declarative kernel language is small and flexible enough that adding the ability to execute code concurrently ends up being simple, at least from a programming language design standpoint.</p>

<blockquote>
  <p>“Our approach to concurrency is a simple extension to the declarative model that allows more than one executing statement to reference the store.”</p>
</blockquote>

<p>A new instruction, <code class="language-plaintext highlighter-rouge">thread</code>, is added to the existing kernel, which gives us the following language:</p>

<center><img src="https://dl.dropboxusercontent.com/u/1401061/declarativeconcurrency.png" />
<div class="lead">The entire data-driven concurrent kernel language, including the new thread instruction. <a href="#bib3">[3]</a></div></center>

<p>The ability for the kernel language to express concurrent programs means that under the right conditions, things can be happening at the same time. The authors do an excellent job of describing what “at the same time” really means, and it’s worth going through the terminology so that we can thoroughly understand the implications of declarative concurrency.</p>

<p>It is said that all operations in a program have a <strong>global sequence</strong> and that threads do an <strong>interleaving execution</strong> over this sequence. A <strong>scheduler</strong> is responsible for choosing work for threads. Concurrency in the kernel language relies on the existence of <strong>single assignment</strong> or <strong>dataflow variables</strong>, the properties of which provide both immutability guarantees and a coordination point for external computation with respect to their <strong>bound/unbound state</strong>.</p>

<p>An execution is <strong>nondeterministic</strong> if the choice of which thread to execute becomes visible to the programmer. In the concurrent declarative kernel language, <em>nondeterminism is never visible.</em>  Simply put, this lack of visible nondeterminism can be attributed to the fact that there is simply no choice but to wait if a variable is not yet bound. There is no chance that two threads will write to the same variable, since variables can only be assigned a value once. Therefore all “reads” will be deterministic and at worse you cannot predict exactly when “writes” will happen.</p>

<p>The <strong>scheduler</strong> which runs the concurrent kernel language is assumed to <strong>fairly</strong> select threads to do work, and never lets any thread <strong>starve</strong>. Threads can be either be <strong>ready</strong> or <strong>suspended</strong>, depending on if they have work to do, or are waiting on other calculations to be complete before their work can proceed. Let’s take a closer look at how threads integrate into the semantics of the kernel language and how it executes in our abstract machine.</p>

<h4 id="the-semantics-of-threads">The Semantics of Threads</h4>
<h4> </h4>
<div class="lead">This section builds on the abstract machine <a href="http://michaelrbernste.in/2013/06/17/declarative-computation-and-the-abstract-machine.html">discussed in this earlier post in the series</a>.</div>

<p>Adding threads to the existing declarative kernel language is a matter of adding a <code class="language-plaintext highlighter-rouge">thread</code> operation. This operation extends the abstract machine by allowing multiple semantic stacks to have access to the same data store.</p>

<p>Intuitively, the difference between a sequential and a concurrent program is reflected in how we introduce concurrency into the abstract machine: before, one total order was possible because only one environment was executed. After, a causal order is guaranteed by the scheduling algorithm and the existence of multiple stacks, each represented by a thread.</p>

<p>We still have the concepts of a <strong>single assignment store ($\sigma$)</strong>, an <strong>environment ($E$)</strong>, a <strong>semantic statement ($&lt; S &gt;, E$)</strong>, and a semantic stack ($ST$). We extend the concept of an <strong>execution state</strong> and <strong>computation</strong> to allow for multiple semantic stacks. An execution state becomes a pair ($MST,\sigma$) where MST is a multiset (which we can think of as a list for our purposes) of semantic stacks and $\sigma$ is the single assignment store. A computation becomes a sequence of execution states which starts at the beginning of the list of semantic stacks, and ends at its end. The choice of which semantic stack to evaluate is up to the scheduler (the implementation of the scheduler is another fascinating subject that this post does not do justice).</p>

<p>Consider the following small sample concurrent program:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">local</span> <span class="no">B</span> <span class="k">in</span>
	<span class="n">thread</span> <span class="no">B</span><span class="o">=</span><span class="kp">true</span> <span class="k">end</span>
	<span class="k">if</span> <span class="no">B</span> <span class="k">then</span> <span class="p">{</span><span class="no">Browse</span> <span class="n">yes</span><span class="p">}</span> <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>This program only has one place to begin, on the first line. <code class="language-plaintext highlighter-rouge">B</code> is introduced into an environment in a semantic stack and then the next line is reached. <code class="language-plaintext highlighter-rouge">thread</code> never blocks, but peels off the work into its own semantic stack to be executed at the scheduler’s convenience. The next line is reached. If <code class="language-plaintext highlighter-rouge">B</code> has been bound by the work done in the computation in the previous step, then this line will display <code class="language-plaintext highlighter-rouge">yes</code> and the program will be complete. There are no circumstances under which this program would behave in any other way under the given semantics.</p>

<h4 id="what-is-declarative-concurrency">What is Declarative Concurrency?</h4>

<p>It has been shown that the “threadless” programs in the preceding chapters are declarative, and we have defined what concurrency means. So what does it mean for a program to be both declarative and concurrent? We know that the basis of declarativeness is that the output of a program should be a mathematical function of its input. Two issues arise with concurrent programming, however - termination is not guaranteed thus output is difficult to measure, and definition as <em>functional</em> is challenging, because programs inputs and outputs can both contain unbound variables. Simply put, we can think of declarative concurrency as <em>concurrency with no observable nondeterminism,</em> but lets spend some time with the technical definition:</p>

<blockquote>
  <p>“A concurrent program is declarative if the following holds for all possible inputs. All executions with a given set of inputs have one of two results: (1) they all do not terminate or (2) they all eventually reach partial termination and give results that are logically equivalent.”</p>
</blockquote>

<p>For programs which do not terminate, we don’t need to illustrate much – they just won’t terminate, and that is true of any time you run them, regardless of externalities.</p>

<p>What does <strong>partial termination</strong> mean? Since we cannot rely on <strong>total termination</strong> in a programming paradigm with streams that can grow indefinitely, we can rely on a partial termination, defined as a stopping point when calculations are temporarily exhausted. Consider the following program:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fun</span> <span class="p">{</span><span class="no">Double</span> <span class="no">Xs</span><span class="p">}</span>
	<span class="k">case</span> <span class="no">Xs</span> <span class="n">of</span> <span class="no">X</span><span class="o">|</span><span class="no">Xr</span> <span class="k">then</span> <span class="mi">2</span><span class="o">*</span><span class="no">X</span><span class="o">|</span><span class="p">{</span><span class="no">Double</span> <span class="no">Xr</span><span class="p">}</span> <span class="k">end</span>
<span class="k">end</span>

<span class="no">Ys</span> <span class="o">=</span> <span class="p">{</span><span class="no">Double</span> <span class="no">Xs</span><span class="p">}</span></code></pre></figure>

<p>This program will run as long as there are values in <code class="language-plaintext highlighter-rouge">Xs</code> to be processed. If there are none, the program will simply be in a state of partial termination. How can we assert the <strong>logical equivalence</strong> of the results of a program such as this? We can essentially rely on our intuition, but a technical explanation exists. Each state of partial termination contains enough information for us to quantify in terms of <strong>constraints</strong>. These constraints allow us to compare states in terms of bound and unbound variables and the values to which they may be bound. Since equivalence on these constraints is defined (but outside the scope of this post), we can assert equivalence on partial termination states even if the total order present in the sequential version doesn’t hold. As long as the causal order is maintained, and no nondeterminism is visible, our concurrent programs can be considered declarative.</p>

<h4 id="programming-with-streams">Programming With Streams</h4>

<p>Streams are given extensive treatment by the authors in Chapter 4 and are referred to as one of the most convenient and reasonable ways to program with declarative concurrency. A special case of stream programming is covered, known as <em>deterministic stream programming</em>, where “each stream object always knows for each input where the next message will come from.” This is a declarative means of stream programming - non-deterministic stream programming is covered in Chapter 5, <em>Message-Passing Concurrency.</em> Though this sounds limiting, some very interesting examples are covered.</p>

<p>The concept behind streams are that they are convenient ways to declaratively express computation as communication between threads. The authors description, as usual, is compact and thorough:</p>

<blockquote>
  <p>“A stream is a potentially unbounded list of messages, i.e., it is a list whose tail is an unbound dataflow variable. Sending a message is done by extending the stream by one element: bind the tail to a list pair containing the message and a new unbound tail. Receiving a message is reading a stream element.”</p>
</blockquote>

<p>Streams and dataflow variables have a natural affinity and the authors capitalize on this insight. They give a nice definition and demonstration of basic use of streams, and begin to explore patterns useful in stream programming, even using streams to perform digital logic simulations.</p>

<p>Declaring a stream looks like this:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">declare</span> <span class="no">Xs</span> <span class="no">Xs2</span> <span class="k">in</span>
<span class="no">Xs</span> <span class="o">=</span> <span class="mi">0</span><span class="o">|</span><span class="mi">1</span><span class="o">|</span><span class="mi">2</span><span class="o">|</span><span class="mi">3</span><span class="o">|</span><span class="no">Xs2</span></code></pre></figure>

<p>Here is how you incrementally extend a stream:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">declare</span> <span class="no">Xs3</span> <span class="k">in</span>
<span class="no">X2</span> <span class="o">=</span> <span class="mi">0</span><span class="o">|</span><span class="mi">1</span><span class="o">|</span><span class="mi">2</span><span class="o">|</span><span class="mi">3</span><span class="o">|</span><span class="no">Xs3</span></code></pre></figure>

<p>And a program that combines these concepts to form a basic <strong>producer/consumer</strong> pattern:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fun</span> <span class="p">{</span><span class="no">Generate</span> <span class="no">N</span> <span class="no">Limit</span><span class="p">}</span>
	<span class="k">if</span> <span class="no">N</span><span class="o">&lt;</span><span class="no">Limit</span> <span class="k">then</span>
		<span class="no">N</span><span class="o">|</span><span class="p">{</span><span class="no">Generate</span> <span class="no">N</span><span class="o">+</span><span class="mi">1</span> <span class="no">Limit</span><span class="p">}</span> 
	<span class="k">else</span> <span class="kp">nil</span> <span class="k">end</span>
<span class="k">end</span>
<span class="n">fun</span> <span class="p">{</span><span class="no">Sum</span> <span class="no">Xs</span> <span class="no">A</span><span class="p">}</span>
	<span class="k">case</span> <span class="no">Xs</span>
	<span class="n">of</span> <span class="no">X</span><span class="o">|</span><span class="no">Xr</span> <span class="k">then</span> <span class="p">{</span><span class="no">Sum</span> <span class="no">Xr</span> <span class="no">A</span><span class="o">+</span><span class="no">X</span><span class="p">}</span>
	<span class="p">[]</span> <span class="kp">nil</span> <span class="k">then</span> <span class="no">A</span>
<span class="k">end</span>
<span class="k">end</span>
<span class="n">local</span> <span class="no">Xs</span> <span class="no">S</span> <span class="k">in</span>
	<span class="c1"># Producer thread</span>
	<span class="n">thread</span> <span class="no">Xs</span><span class="o">=</span><span class="p">{</span><span class="no">Generate</span> <span class="mi">0</span> <span class="mi">150000</span><span class="p">}</span> <span class="k">end</span> 
	<span class="c1"># Consumer thread</span>
	<span class="n">thread</span> <span class="no">S</span><span class="o">=</span><span class="p">{</span><span class="no">Sum</span> <span class="no">Xs</span> <span class="mi">0</span><span class="p">}</span> <span class="k">end</span> 
	<span class="c1"># Display results				  </span>
	<span class="p">{</span><span class="no">Browse</span> <span class="no">S</span><span class="p">}</span>
<span class="k">end</span></code></pre></figure>

<p>Producer and consumer each run in their own threads, operating on the shared dataflow variable <code class="language-plaintext highlighter-rouge">Xs</code>. As data is appended to the stream by <code class="language-plaintext highlighter-rouge">Generate</code>, it is consumed by <code class="language-plaintext highlighter-rouge">Sum</code>.  The <code class="language-plaintext highlighter-rouge">case</code> statement in <code class="language-plaintext highlighter-rouge">Sum</code> blocks when there are no available values to bind, and calculates values when they are there to be read. As the authors say, “Waiting for a dataflow variable to be bound is the basic mechanism for synchronization and communication in the declarative concurrent model.”</p>

<p>You can use this same basic program to have multiple consumers and producers, or create a <em>pipeline</em> of filters:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">local</span> <span class="no">Xs</span> <span class="no">Ys</span> <span class="no">S</span> <span class="k">in</span>
	<span class="n">thread</span> <span class="no">Xs</span><span class="o">=</span><span class="p">{</span><span class="no">Generate</span> <span class="mi">0</span> <span class="mi">15000</span><span class="p">}</span> <span class="k">end</span>
	<span class="n">thread</span> <span class="no">Ys</span><span class="o">=</span><span class="p">{</span><span class="no">Filter</span> <span class="no">Xs</span> <span class="no">IsOdd</span><span class="p">}</span> <span class="k">end</span>
	<span class="n">thread</span> <span class="no">S</span><span class="o">=</span><span class="p">{</span><span class="no">Sum</span> <span class="no">Ys</span> <span class="mi">0</span> <span class="p">}</span> <span class="k">end</span>
	<span class="p">{</span><span class="no">Browse</span> <span class="no">S</span><span class="p">}</span>
<span class="k">end</span></code></pre></figure>

<p>And when streams are generalized to “a recursive procedure that executes in its own thread and communicates with other stream objects through input and output streams,” things really start to get wild: simple declarative concurrency primitives when combined can produce powerful results.</p>

<h4 id="conclusion">Conclusion</h4>

<p>The authors have shown us yet again that simple extension of the semantics of the kernel language can make very sophisticated programs possible with seemingly limited resources. Concurrency and its application in modern software design is of paramount importance as our “free lunch” has long been over but we struggle in denial against its reality, often wielding primitive, wasteful tools.<a href="#bib2">[2]</a> Our tools rely on syntactic and semantic constructions which force us to amortize the costs of writing our programs over a very long period of time - they are easy to create, but difficult to maintain. Some of these constructions include (faux, overloaded) Object Orientation, global state, and mutability.</p>

<p><em>Mutability</em> refers to the ability of the programmer to change the value of an <em>object</em> after it has been instantiated (<em>object</em> is an abstract name given to any assignable quantity that developers have access to). Much discussion has been raised specifically surrounding the connection between mutability and the inability for our tools to properly handle concurrency in a reasonable way, and in fact we are making progress.<a id="bib1">[1]</a> Several active programming languages, including the Mozart platform that the CTM book constructs, Clojure, which runs on the Java Virtual Machine, and Haskell all have embraced the value of immutability and the leverage it gives programming language designers in providing <em>simpler concurrency</em>.</p>

<p>Beginning professional developers who jump right in to programming with mutable, global state, objects, and concurrency rightfully believe that “concurrency in <strong>LANGUAGE X</strong> is Hard.” Unfortunately, many people extend that to “programming with concurrency is Hard.” They don’t seek other paradigms because they think that the complexity is necessary. They think it is capital-H Hard and the truth is that it doesn’t have to be.</p>

<h4 id="works-cited">Works Cited</h4>

<p><em>All quotes unless otherwise cited from Van Roy and Haridi.</em></p>

<p><a id="bib1">[1]</a> Hickey, Rich. <em>Index of Published Talks</em> <a href="http://www.infoq.com/author/Rich-Hickey">HTML Page</a></p>

<p><a id="bib2">[2]</a> Sutter, Herb. <em>A Fundamental Turn Toward Concurrency in Software</em> Dr. Dobbs Software Journal. <a href="http://www.drdobbs.com/article/print?articleId=184405990&amp;siteSectionName=web-development/">Available here.</a></p>

<p><a id="bib3">[3]</a> Van Roy and Haridi. <em>Concepts, Techniques, and Models of Computer Programming</em> MIT Press, hardcover, ISBN 0-262-22069-5, March 2004</p>
:ET